#!/usr/bin/env python3
"""
é€šç”¨Stable Diffusionæµ‹è¯•é…ç½®ç”Ÿæˆå™¨
æ”¯æŒå¤šç§æœºå‹ã€æ‰¹æ¬¡å¤§å°ã€æ¨ç†æ­¥æ•°ã€åˆ†è¾¨ç‡å’Œç²¾åº¦
æ”¯æŒæ ‡å‡†SDæ¨¡å‹å’ŒSDXLæ¨¡å‹çš„æ™ºèƒ½é…ç½®
"""

import json
import argparse
import itertools
from datetime import datetime

def generate_test_config(
    models=None,
    instance_types=None,
    batch_sizes=None,
    inference_steps=None,
    resolutions=None,
    precisions=None,
    prompt="a photo of an astronaut riding a horse on mars",
    output_file="universal_test_config.json",
    test_mode="mixed",
    comparison_memory_request="12Gi",
    comparison_memory_limit="15Gi",
    comparison_timeout=2400
):
    """ç”Ÿæˆé€šç”¨æµ‹è¯•é…ç½®"""
    
    # æ ¹æ®æµ‹è¯•æ¨¡å¼è®¾ç½®é»˜è®¤å€¼
    if test_mode == "sdxl_only":
        # SDXLä¸“ç”¨æ¨¡å¼
        if models is None:
            models = ["stabilityai/stable-diffusion-xl-base-1.0"]
        if instance_types is None:
            instance_types = ["g6e.xlarge", "g5.xlarge", "g6.xlarge"]
        if batch_sizes is None:
            batch_sizes = [1]
        if inference_steps is None:
            inference_steps = [20, 30, 50]
        if resolutions is None:
            resolutions = ["1024x1024", "1152x896", "896x1152"]
        if precisions is None:
            precisions = ["float16"]
    elif test_mode == "sd_only":
        # æ ‡å‡†SDä¸“ç”¨æ¨¡å¼
        if models is None:
            models = ["stabilityai/stable-diffusion-2-1"]
        if instance_types is None:
            instance_types = ["g5.xlarge", "g6.xlarge"]
        if batch_sizes is None:
            batch_sizes = [1, 4]
        if inference_steps is None:
            inference_steps = [15, 25, 50]
        if resolutions is None:
            resolutions = ["512x512", "1024x1024"]
        if precisions is None:
            precisions = ["float16", "float32"]
    elif test_mode == "comparison":
        # å¯¹æ¯”æ¨¡å¼
        if models is None:
            models = ["stabilityai/stable-diffusion-2-1", "stabilityai/stable-diffusion-xl-base-1.0"]
        if instance_types is None:
            instance_types = ["g6e.xlarge", "g5.xlarge", "g6.xlarge"]
        if batch_sizes is None:
            batch_sizes = [1]
        if inference_steps is None:
            inference_steps = [20, 30]
        if resolutions is None:
            resolutions = ["1024x1024"]
        if precisions is None:
            precisions = ["float16"]
    elif test_mode == "instance_optimized":
        # å®ä¾‹ä¼˜åŒ–æ¨¡å¼ - é’ˆå¯¹ä¸åŒå®ä¾‹ç±»å‹çš„æœ€ä½³é…ç½®
        if models is None:
            models = ["stabilityai/stable-diffusion-xl-base-1.0"]
        if instance_types is None:
            instance_types = ["g6e.xlarge", "g5.xlarge", "g6.xlarge", "g4dn.xlarge"]
        if batch_sizes is None:
            batch_sizes = [1]
        if inference_steps is None:
            inference_steps = [20]
        if resolutions is None:
            # æ ¹æ®å®ä¾‹ç±»å‹åŠ¨æ€è°ƒæ•´åˆ†è¾¨ç‡
            resolutions = ["1024x1024", "896x896"]  # åŒ…å«å¤‡ç”¨åˆ†è¾¨ç‡
        if precisions is None:
            precisions = ["float16"]
    else:
        # æ··åˆæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
        if models is None:
            models = ["stabilityai/stable-diffusion-2-1"]
        if instance_types is None:
            instance_types = ["g5.xlarge"]
        if batch_sizes is None:
            batch_sizes = [1, 4]
        if inference_steps is None:
            inference_steps = [15, 25, 50]
        if resolutions is None:
            resolutions = ["1024x1024"]
        if precisions is None:
            precisions = ["float32"]
    
    # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
    combinations = list(itertools.product(
        models, instance_types, batch_sizes, inference_steps, resolutions, precisions
    ))
    
    tests = []
    for i, (model, instance, batch, steps, resolution, precision) in enumerate(combinations):
        # è§£æåˆ†è¾¨ç‡
        width, height = map(int, resolution.split('x'))
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºSDXLæ¨¡å‹
        is_sdxl = 'stable-diffusion-xl' in model or 'sdxl' in model.lower()
        
        # æ™ºèƒ½é…ç½®éªŒè¯å’Œè°ƒæ•´
        adjusted_config = validate_and_adjust_config(
            model, instance, batch, steps, width, height, precision, is_sdxl, test_mode,
            comparison_memory_request, comparison_memory_limit, comparison_timeout
        )
        
        if adjusted_config is None:
            continue  # è·³è¿‡ä¸å…¼å®¹çš„é…ç½®
        
        model, instance, batch, steps, width, height, precision, memory_request, memory_limit, timeout = adjusted_config
        
        # ç”Ÿæˆç®€çŸ­çš„æµ‹è¯•åç§°
        model_short = model.split('/')[-1].replace('stable-diffusion-', 'sd-').replace('.', '-')
        if 'xl' in model_short:
            model_short = model_short.replace('sd-xl-', 'sdxl-')
        instance_short = instance.replace('.', '')
        test_name = f"{model_short}-{instance_short}-b{batch}-s{steps}-{precision}"
        
        # ç¡®ä¿åç§°ä¸è¶…è¿‡50ä¸ªå­—ç¬¦
        if len(test_name) > 50:
            test_name = test_name[:50]
        
        test = {
            "name": test_name,
            "description": f"{model} test: {instance}, batch={batch}, steps={steps}, {width}x{height}, {precision}",
            "model": model,
            "model_type": "SDXL" if is_sdxl else "Standard SD",
            "instance_type": instance,
            "batch_size": batch,
            "inference_steps": steps,
            "image_width": width,
            "image_height": height,
            "precision": precision,
            "prompt": prompt,
            "memory_request": memory_request,
            "memory_limit": memory_limit,
            "timeout": timeout
        }
        tests.append(test)
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config = {
        "description": f"Universal Stable Diffusion test configuration - {test_mode} mode",
        "version": "1.0",
        "test_mode": test_mode,
        "generated_by": "generate_universal_test_config.py",
        "generated_at": datetime.now().isoformat(),
        "total_tests": len(tests),
        "instance_specifications": {
            "g6e.xlarge": {"cpu_memory": "32GB", "gpu_memory": "48GB", "sdxl_status": "EXCELLENT"},
            "g5.xlarge": {"cpu_memory": "16GB", "gpu_memory": "24GB", "sdxl_status": "GOOD"},
            "g6.xlarge": {"cpu_memory": "16GB", "gpu_memory": "24GB", "sdxl_status": "GOOD"},
            "g4dn.xlarge": {"cpu_memory": "16GB", "gpu_memory": "16GB", "sdxl_status": "NOT_RECOMMENDED"}
        },
        "default_settings": {
            "prompt": prompt,
            "timeout": 1800,
            "method": "universal_intelligent"
        },
        "test_matrix": {
            "models": models,
            "instance_types": instance_types,
            "batch_sizes": batch_sizes,
            "inference_steps": inference_steps,
            "resolutions": resolutions,
            "precisions": precisions
        },
        "tests": tests
    }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ç”Ÿæˆäº† {len(tests)} ä¸ªæµ‹è¯•é…ç½® ({test_mode} æ¨¡å¼)")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ”§ æµ‹è¯•çŸ©é˜µ:")
    print(f"   æ¨¡å‹: {', '.join(models)}")
    print(f"   å®ä¾‹ç±»å‹: {', '.join(instance_types)}")
    print(f"   æ‰¹æ¬¡å¤§å°: {', '.join(map(str, batch_sizes))}")
    print(f"   æ¨ç†æ­¥æ•°: {', '.join(map(str, inference_steps))}")
    print(f"   åˆ†è¾¨ç‡: {', '.join(resolutions)}")
    print(f"   ç²¾åº¦: {', '.join(precisions)}")
    print(f"   æç¤ºè¯: {prompt}")
    
    # æ˜¾ç¤ºæ¨¡å¼ç‰¹å®šä¿¡æ¯
    if test_mode == "sdxl_only":
        print(f"\nğŸ¯ SDXLä¸“ç”¨æ¨¡å¼ç‰¹æ€§:")
        print(f"   âœ… é’ˆå¯¹SDXLä¼˜åŒ–çš„å®ä¾‹ç±»å‹")
        print(f"   âœ… å¼ºåˆ¶ä½¿ç”¨float16ç²¾åº¦")
        print(f"   âœ… åŸç”Ÿ1024x1024åˆ†è¾¨ç‡")
        print(f"   âœ… æ™ºèƒ½å†…å­˜é…ç½®")
    elif test_mode == "comparison":
        print(f"\nğŸ“Š å¯¹æ¯”æ¨¡å¼ç‰¹æ€§:")
        print(f"   âœ… SD 2.1 vs SDXL æ€§èƒ½å¯¹æ¯”")
        print(f"   âœ… ç»Ÿä¸€èµ„æºé…ç½®ç¡®ä¿å…¬å¹³å¯¹æ¯”")
        print(f"   âœ… æ‰€æœ‰æµ‹è¯•ä½¿ç”¨ç›¸åŒçš„CPUå†…å­˜é…ç½®")
        print(f"   âœ… å°Šé‡ç”¨æˆ·æŒ‡å®šçš„ç²¾åº¦å’Œæ‰¹æ¬¡å¤§å°")
        print(f"   âš ï¸  ç”¨æˆ·éœ€è¦è‡ªè¡Œç¡®ä¿é…ç½®åˆç†æ€§ï¼ˆé¿å…OOMç­‰é—®é¢˜ï¼‰")
        print(f"   ğŸ“‹ ç»Ÿä¸€é…ç½®: {comparison_memory_request}/{comparison_memory_limit} CPUå†…å­˜, ç”¨æˆ·æŒ‡å®šç²¾åº¦, timeout={comparison_timeout}s")
    elif test_mode == "instance_optimized":
        print(f"\nğŸ”§ å®ä¾‹ä¼˜åŒ–æ¨¡å¼ç‰¹æ€§:")
        print(f"   âœ… é’ˆå¯¹æ¯ä¸ªå®ä¾‹ç±»å‹çš„æœ€ä½³é…ç½®")
        print(f"   âœ… è‡ªåŠ¨è·³è¿‡ä¸å…¼å®¹é…ç½®")
        print(f"   âœ… åŒ…å«å¤‡ç”¨åˆ†è¾¨ç‡")
    
    print(f"\nğŸš€ è¿è¡Œæµ‹è¯•:")
    print(f"   chmod +x run_universal_tests.sh")
    print(f"   ./run_universal_tests.sh {output_file}")
    
    return config

def validate_and_adjust_config(model, instance, batch, steps, width, height, precision, is_sdxl, test_mode, 
                              comparison_memory_request="12Gi", comparison_memory_limit="15Gi", comparison_timeout=2400):
    """éªŒè¯å’Œè°ƒæ•´é…ç½®ï¼Œç¡®ä¿å…¼å®¹æ€§"""
    
    # å¯¹æ¯”æ¨¡å¼ä¸‹ä½¿ç”¨ç»Ÿä¸€é…ç½®ï¼Œç¡®ä¿å…¬å¹³å¯¹æ¯”
    if test_mode == "comparison":
        # å¯¹æ¯”æ¨¡å¼ï¼šæ‰€æœ‰æµ‹è¯•ä½¿ç”¨ç›¸åŒçš„èµ„æºé…ç½®
        # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å†…å­˜é…ç½®
        memory_request = comparison_memory_request
        memory_limit = comparison_memory_limit
        timeout = comparison_timeout
        
        # ä¿æŒç”¨æˆ·æŒ‡å®šçš„ç²¾åº¦å’Œæ‰¹æ¬¡å¤§å°ï¼Œä¸å¼ºåˆ¶ä¿®æ”¹
        # ç”¨æˆ·éœ€è¦è‡ªå·±ç¡®ä¿é…ç½®çš„åˆç†æ€§
        return model, instance, batch, steps, width, height, precision, memory_request, memory_limit, timeout
    
    # éå¯¹æ¯”æ¨¡å¼ä¸‹çš„æ™ºèƒ½é…ç½®è°ƒæ•´
    # SDXLåœ¨g4dn.xlargeä¸Šä¸æ¨èï¼Œé™¤éæ˜¯instance_optimizedæ¨¡å¼
    if is_sdxl and 'g4dn.xlarge' in instance and test_mode != "instance_optimized":
        return None  # è·³è¿‡ä¸å…¼å®¹é…ç½®
    
    # åœ¨éå¯¹æ¯”æ¨¡å¼ä¸‹ï¼Œä»ç„¶è¿›è¡Œä¸€äº›æ™ºèƒ½è°ƒæ•´ä»¥é¿å…æ˜æ˜¾çš„é—®é¢˜
    # ä½†ç”¨æˆ·å¯ä»¥é€šè¿‡é€‰æ‹©åˆé€‚çš„æ¨¡å¼æ¥é¿å…è¿™äº›è°ƒæ•´
    
    # SDXLå¿…é¡»ä½¿ç”¨float16åœ¨å°GPUå†…å­˜å®ä¾‹ä¸Šï¼ˆä»…åœ¨éå¯¹æ¯”æ¨¡å¼ä¸‹è°ƒæ•´ï¼‰
    if is_sdxl and instance in ['g5.xlarge', 'g6.xlarge', 'g4dn.xlarge'] and precision != 'float16':
        precision = 'float16'  # è‡ªåŠ¨è°ƒæ•´
    
    # SDXLåœ¨å°GPUå†…å­˜å®ä¾‹ä¸Šæ‰¹æ¬¡å¤§å°é™åˆ¶ä¸º1ï¼ˆä»…åœ¨éå¯¹æ¯”æ¨¡å¼ä¸‹è°ƒæ•´ï¼‰
    if is_sdxl and instance in ['g5.xlarge', 'g6.xlarge', 'g4dn.xlarge'] and batch > 1:
        batch = 1  # è‡ªåŠ¨è°ƒæ•´
    
    # g4dn.xlargeä¸Šçš„SDXLé™ä½åˆ†è¾¨ç‡ï¼ˆä»…åœ¨éå¯¹æ¯”æ¨¡å¼ä¸‹è°ƒæ•´ï¼‰
    if is_sdxl and 'g4dn.xlarge' in instance and width >= 1024:
        width, height = 896, 896  # é™ä½åˆ°æ›´å®‰å…¨çš„åˆ†è¾¨ç‡
    
    # æ ¹æ®å®ä¾‹ç±»å‹å’Œæ¨¡å‹è®¾ç½®CPUå†…å­˜
    if 'g6e.xlarge' in instance:
        # g6e.xlarge: 32GB CPUå†…å­˜, 48GB GPUå†…å­˜
        if is_sdxl:
            memory_request = "16Gi"
            memory_limit = "24Gi"
            timeout = 2400
        else:
            memory_request = "12Gi"
            memory_limit = "20Gi"
            timeout = 1800
    elif 'g5.xlarge' in instance or 'g6.xlarge' in instance:
        # g5/g6.xlarge: 16GB CPUå†…å­˜, 24GB GPUå†…å­˜
        if is_sdxl:
            memory_request = "8Gi"
            memory_limit = "12Gi"
            timeout = 2400
        else:
            memory_request = "6Gi"
            memory_limit = "10Gi"
            timeout = 1800
    elif 'g4dn.xlarge' in instance:
        # g4dn.xlarge: 16GB CPUå†…å­˜, 16GB GPUå†…å­˜
        if is_sdxl:
            memory_request = "8Gi"
            memory_limit = "12Gi"
            timeout = 3000  # æ›´é•¿è¶…æ—¶ï¼Œå› ä¸ºå¯èƒ½å¾ˆæ…¢
        else:
            memory_request = "6Gi"
            memory_limit = "10Gi"
            timeout = 1800
    else:
        # é»˜è®¤é…ç½®
        if is_sdxl:
            memory_request = "8Gi"
            memory_limit = "12Gi"
            timeout = 2400
        else:
            memory_request = "6Gi"
            memory_limit = "10Gi"
            timeout = 1800
    
    return model, instance, batch, steps, width, height, precision, memory_request, memory_limit, timeout

def main():
    parser = argparse.ArgumentParser(description='ç”Ÿæˆé€šç”¨Stable Diffusionæµ‹è¯•é…ç½®')
    
    # æµ‹è¯•æ¨¡å¼é€‰æ‹©
    parser.add_argument('--mode', choices=['mixed', 'sdxl_only', 'sd_only', 'comparison', 'instance_optimized'],
                       default='mixed',
                       help='æµ‹è¯•æ¨¡å¼: mixed(æ··åˆ), sdxl_only(ä»…SDXL), sd_only(ä»…æ ‡å‡†SD), comparison(å¯¹æ¯”), instance_optimized(å®ä¾‹ä¼˜åŒ–)')
    
    parser.add_argument('--models', nargs='+', 
                       help='æ¨¡å‹åˆ—è¡¨ (é»˜è®¤æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©)')
    
    parser.add_argument('--instance-types', nargs='+',
                       help='å®ä¾‹ç±»å‹åˆ—è¡¨ (é»˜è®¤æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©)')
    
    parser.add_argument('--batch-sizes', nargs='+', type=int,
                       help='æ‰¹æ¬¡å¤§å°åˆ—è¡¨ (é»˜è®¤æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©)')
    
    parser.add_argument('--inference-steps', nargs='+', type=int,
                       help='æ¨ç†æ­¥æ•°åˆ—è¡¨ (é»˜è®¤æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©)')
    
    parser.add_argument('--resolutions', nargs='+',
                       help='åˆ†è¾¨ç‡åˆ—è¡¨ (é»˜è®¤æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©)')
    
    parser.add_argument('--precisions', nargs='+',
                       help='ç²¾åº¦åˆ—è¡¨ (é»˜è®¤æ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©)')
    
    parser.add_argument('--prompt',
                       default="a photo of an astronaut riding a horse on mars",
                       help='æç¤ºè¯ (é»˜è®¤: a photo of an astronaut riding a horse on mars)')
    
    parser.add_argument('--output', '-o',
                       default="universal_test_config.json",
                       help='è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: universal_test_config.json)')
    
    # å¯¹æ¯”æ¨¡å¼ä¸“ç”¨å‚æ•°
    parser.add_argument('--comparison-memory-request',
                       default="12Gi",
                       help='å¯¹æ¯”æ¨¡å¼CPUå†…å­˜è¯·æ±‚ (é»˜è®¤: 12Giï¼Œé€‚åˆ16GBå†…å­˜æœºå™¨)')
    
    parser.add_argument('--comparison-memory-limit',
                       default="15Gi", 
                       help='å¯¹æ¯”æ¨¡å¼CPUå†…å­˜é™åˆ¶ (é»˜è®¤: 15Giï¼Œæ›´å¥½åˆ©ç”¨ç¡¬ä»¶èµ„æº)')
    
    parser.add_argument('--comparison-timeout', type=int,
                       default=2400,
                       help='å¯¹æ¯”æ¨¡å¼è¶…æ—¶æ—¶é—´ç§’æ•° (é»˜è®¤: 2400ç§’/40åˆ†é’Ÿ)')
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºæ¨¡å¼è¯´æ˜
    mode_descriptions = {
        'mixed': 'æ··åˆæ¨¡å¼ - æ ‡å‡†é…ç½®ï¼Œé€‚åˆä¸€èˆ¬æµ‹è¯•',
        'sdxl_only': 'SDXLä¸“ç”¨æ¨¡å¼ - é’ˆå¯¹SDXLä¼˜åŒ–çš„é…ç½®',
        'sd_only': 'æ ‡å‡†SDä¸“ç”¨æ¨¡å¼ - ä»…æµ‹è¯•æ ‡å‡†SDæ¨¡å‹',
        'comparison': 'å¯¹æ¯”æ¨¡å¼ - SD 2.1 vs SDXL æ€§èƒ½å¯¹æ¯”',
        'instance_optimized': 'å®ä¾‹ä¼˜åŒ–æ¨¡å¼ - é’ˆå¯¹ä¸åŒå®ä¾‹ç±»å‹çš„æœ€ä½³é…ç½®'
    }
    
    print(f"ğŸ¯ é€‰æ‹©çš„æµ‹è¯•æ¨¡å¼: {args.mode}")
    print(f"ğŸ“ æ¨¡å¼è¯´æ˜: {mode_descriptions[args.mode]}")
    
    # æ˜¾ç¤ºå¯¹æ¯”æ¨¡å¼çš„å†…å­˜é…ç½®å»ºè®®
    if args.mode == "comparison":
        print(f"\nğŸ’¡ å¯¹æ¯”æ¨¡å¼å†…å­˜é…ç½®å»ºè®®:")
        print(f"   16GB CPUå†…å­˜æœºå™¨: --comparison-memory-request 12Gi --comparison-memory-limit 15Gi (é»˜è®¤)")
        print(f"   32GB CPUå†…å­˜æœºå™¨: --comparison-memory-request 24Gi --comparison-memory-limit 30Gi")
        print(f"   ä¿å®ˆé…ç½® (å¦‚æœ‰å…¶ä»–å·¥ä½œè´Ÿè½½): --comparison-memory-request 8Gi --comparison-memory-limit 12Gi")
        print(f"   å½“å‰é…ç½®: {args.comparison_memory_request}/{args.comparison_memory_limit}, è¶…æ—¶{args.comparison_timeout}ç§’")
    
    print()
    
    generate_test_config(
        models=args.models,
        instance_types=args.instance_types,
        batch_sizes=args.batch_sizes,
        inference_steps=args.inference_steps,
        resolutions=args.resolutions,
        precisions=args.precisions,
        prompt=args.prompt,
        output_file=args.output,
        test_mode=args.mode,
        comparison_memory_request=args.comparison_memory_request,
        comparison_memory_limit=args.comparison_memory_limit,
        comparison_timeout=args.comparison_timeout
    )

if __name__ == "__main__":
    main()
